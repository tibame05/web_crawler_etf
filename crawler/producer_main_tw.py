# crawler/producer_main_tw.py
import pandas as pd
from crawler.tasks_etf_list_tw import scrape_etf_list  # åŒ¯å…¥çˆ¬ ETF æ¸…å–®çš„å‡½å¼
from crawler.tasks_crawler_etf_tw import (
    crawler_etf_daily_price,
    crawler_etf_dividend,
)  # åŒ¯å…¥çˆ¬å– ETF æ­·å²åƒ¹æ ¼èˆ‡é…æ¯çš„å‡½å¼
from crawler.tasks_backtest_utils_tw import (
    calculate_indicators,
    evaluate_performance,
)  # åŒ¯å…¥æŠ€è¡“æŒ‡æ¨™èˆ‡ç¸¾æ•ˆåˆ†æçš„å‡½å¼


if __name__ == "__main__":
    # æ§åˆ¶æ˜¯å¦è¦å­˜ CSV
    SAVE_CSV = False


    # 0ï¸âƒ£ å…ˆçˆ¬ ETF æ¸…å–®ï¼ˆåç¨±èˆ‡ä»£è™Ÿï¼‰ï¼Œä¸¦å„²å­˜æˆ etf_list.csv
    print("é–‹å§‹ 0ï¸âƒ£ çˆ¬ ETF æ¸…å–®")
    etfs = scrape_etf_list.apply_async(
        kwargs={"save_csv": SAVE_CSV}, queue="crawler_tw"
    ).get()
    etfs_df = pd.DataFrame(etfs)
    print(f"çˆ¬å–åˆ° {len(etfs_df)} ç­† ETF è³‡æ–™")
    print("âœ… çˆ¬å–åˆ°æ‰€æœ‰ ETF list")


    # 1ï¸âƒ£~3ï¸âƒ£ æ¯ä¸€æ”¯ ETF éƒ½è¦åšçš„äº‹æƒ…
    print("é–‹å§‹ ğŸ§© è™•ç†æ‰€æœ‰ ETF è³‡æ–™")
    ticker_list = etfs_df["etf_id"].dropna().tolist()

    for ticker in ticker_list:
        print(f"\nğŸ¯ è™•ç†ï¼š{ticker}")

        try:
            # === 1ï¸âƒ£ æŠ“æ­·å²åƒ¹æ ¼ + æŠ€è¡“æŒ‡æ¨™è¨ˆç®— ===
            # df_price = crawler_etf_daily_price.apply_async(args=[ticker], queue="crawler_tw").get()
            daily_price = crawler_etf_daily_price.apply_async(
                args=[ticker], queue="crawler_tw"
            ).get()
            df_price = pd.DataFrame(daily_price)
            print(df_price.head())   # â† æª¢æŸ¥æ­·å²åƒ¹æ ¼è³‡æ–™
            #print(df_price.columns)  # â† ç¢ºèªæ¬„ä½åç¨±å°ä¸å°
            if df_price.empty:
                print(f"âš ï¸ ç„¡æ­·å²åƒ¹æ ¼è³‡æ–™ï¼š{ticker}")
                continue

            # æª¢æŸ¥æ—¥æœŸæ¬„ä½æ˜¯å¦ç‚º datetime æ ¼å¼ï¼Œå†åŠ ä¸ŠæŠ€è¡“æŒ‡æ¨™æ¬„ä½
            df_price["date"] = pd.to_datetime(df_price["date"])
            # df_combined = calculate_indicators.apply_async(args=[df_price], queue="crawler_tw").get()
            combined = calculate_indicators.apply_async(
                args=[df_price], queue="crawler_tw"
            ).get()
            df_combined = pd.DataFrame(combined)
            print(f"âœ… {ticker} æ­·å²åƒ¹æ ¼èˆ‡æŠ€è¡“æŒ‡æ¨™å·²å„²å­˜")

            # === 2ï¸âƒ£ æŠ“é…æ¯è³‡æ–™ ===
            # df_dividend = crawler_etf_dividend.apply_async(args=[ticker], queue="crawler_tw").get()
            crawler_etf_dividend.apply_async(args=[ticker], queue="crawler_tw")

            # === 3ï¸âƒ£ ç¸¾æ•ˆåˆ†æ ===
            # metrics = evaluate_performance.apply_async(args=[df_combined]).get()
            evaluate_performance.apply_async(
                args=[df_combined, ticker], queue="crawler_tw"
            )

        except Exception as e:
            print(f"âŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{ticker} - {e}")

    print("âœ… å…¨éƒ¨ ETF è³‡æ–™è™•ç†å®Œæˆ")


